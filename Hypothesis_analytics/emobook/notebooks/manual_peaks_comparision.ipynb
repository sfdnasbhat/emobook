{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dfafec4-43db-45b7-8af8-9be7b1cf472b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHUNK_DIR: /Users/nageshs/Desktop/college/emobook/emobook/chunks\n",
      "SCORED_DIR: /Users/nageshs/Desktop/college/emobook/emobook/scored_v21\n",
      "OUT_DIR: /Users/nageshs/Desktop/college/emobook/emobook/notebooks/turning_points\n"
     ]
    }
   ],
   "source": [
    "# --- Robust paths: works from repo root OR notebooks/ ----------------------\n",
    "from pathlib import Path\n",
    "\n",
    "BASE = Path.cwd()\n",
    "\n",
    "def pick_dir(label, candidates, must_contain=None, pattern=None):\n",
    "    \"\"\"\n",
    "    Pick the first existing directory that either contains a specific file\n",
    "    or at least one file matching a glob `pattern`.\n",
    "    \"\"\"\n",
    "    for rel in candidates:\n",
    "        d = (BASE / rel).resolve()\n",
    "        if not d.exists():\n",
    "            continue\n",
    "        if must_contain and not (d / must_contain).exists():\n",
    "            if pattern:\n",
    "                if not list(d.glob(pattern)):\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "        print(f\"{label}: {d}\")\n",
    "        return d\n",
    "    raise FileNotFoundError(f\"Couldn't find {label}. Tried: {candidates}\")\n",
    "\n",
    "# find chunks dir (has *.chunks.csv)\n",
    "CHUNK_DIR = pick_dir(\n",
    "    \"CHUNK_DIR\",\n",
    "    [\"chunks\", \"../chunks\", \"../../chunks\"],\n",
    "    pattern=\"*.chunks.csv\",\n",
    ")\n",
    "\n",
    "# find scored dir (prefer scored_v21/, else scored/)\n",
    "SCORED_DIR = pick_dir(\n",
    "    \"SCORED_DIR\",\n",
    "    [\"scored_v21\", \"../scored_v21\", \"../../scored_v21\", \"scored\", \"../scored\", \"../../scored\"],\n",
    "    pattern=\"*.scored_v21.csv\",\n",
    ")\n",
    "\n",
    "# where to write turning-point outputs (put at repo root by default)\n",
    "OUT_DIR = (BASE / \"turning_points\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"OUT_DIR:\", OUT_DIR.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfa4e5e8-f3c9-433d-ac72-de38f5f200ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TURNING-POINT TAGGER + V vs VAD COMPARISON\n",
    "# ------------------------------------------\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re, textwrap\n",
    "\n",
    "\n",
    "\n",
    "# ---- Helpers ----------------------------------------------------------------\n",
    "def _read_csv_maybe(path):\n",
    "    if not path.exists():\n",
    "        raise FileNotFoundError(f\"Missing: {path}\")\n",
    "    return pd.read_csv(path)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_book_frames(book_stem: str, roll_win_default=15):\n",
    "    \"\"\"\n",
    "    Join chunk texts (from CHUNK_DIR) with scores (from SCORED_DIR).\n",
    "    Ensures v_roll/a_roll/d_roll and vad_fused exist.\n",
    "    \"\"\"\n",
    "    chunks_path = CHUNK_DIR / f\"{book_stem}.chunks.csv\"\n",
    "    scored_path = SCORED_DIR / f\"{book_stem}.scored_v21.csv\"\n",
    "\n",
    "    if not chunks_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing chunk CSV: {chunks_path}\")\n",
    "    if not scored_path.exists():\n",
    "        # fallback: pick any scored file that matches the stem\n",
    "        cand = list(SCORED_DIR.glob(f\"{book_stem}*.scored*.csv\"))\n",
    "        if not cand:\n",
    "            raise FileNotFoundError(f\"Missing scored CSV: {scored_path}\")\n",
    "        scored_path = cand[0]\n",
    "\n",
    "    df_chunks = pd.read_csv(chunks_path)\n",
    "    df_scored = pd.read_csv(scored_path)\n",
    "\n",
    "    if \"chunk_id\" not in df_chunks: df_chunks[\"chunk_id\"] = np.arange(len(df_chunks))\n",
    "    if \"chunk_id\" not in df_scored: df_scored[\"chunk_id\"] = np.arange(len(df_scored))\n",
    "\n",
    "    # prefer text from chunks if scored lacks it\n",
    "    base = (df_scored.merge(\n",
    "                df_chunks[[\"chunk_id\",\"text\"]],\n",
    "                on=\"chunk_id\", how=\"left\", suffixes=(\"\", \"_from_chunks\"))\n",
    "            .assign(text=lambda d: d[\"text\"].fillna(d.get(\"text_from_chunks\"))))\n",
    "\n",
    "    # ensure rolled cols\n",
    "    for raw, roll in [(\"v\",\"v_roll\"), (\"a\",\"a_roll\"), (\"d\",\"d_roll\")]:\n",
    "        if roll not in base.columns:\n",
    "            if raw in base.columns:\n",
    "                base[roll] = base[raw].rolling(roll_win_default, center=True, min_periods=1).mean()\n",
    "            else:\n",
    "                base[roll] = np.nan\n",
    "\n",
    "    # ensure fused (if your scored_v21 already has it, this is no-op)\n",
    "    if \"vad_fused\" not in base.columns:\n",
    "        signed = np.sign(base[\"v_roll\"].astype(float))\n",
    "        mag = np.sqrt(base[\"v_roll\"]**2 + base[\"a_roll\"]**2 + base[\"d_roll\"]**2).astype(float)\n",
    "        base[\"vad_fused\"] = signed * mag\n",
    "\n",
    "    for c in [\"v_roll\",\"a_roll\",\"d_roll\",\"vad_fused\"]:\n",
    "        base[c] = pd.to_numeric(base[c], errors=\"coerce\")\n",
    "\n",
    "    return base.sort_values(\"chunk_id\").reset_index(drop=True)\n",
    "\n",
    "\n",
    "def zscore(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return (x - np.nanmean(x)) / (np.nanstd(x) + 1e-8)\n",
    "\n",
    "def find_chunks_for_keywords(text_series, any_terms=None, all_terms=None, regex=None):\n",
    "    \"\"\"\n",
    "    Returns list of indices whose chunk text matches (case-insensitive):\n",
    "      - any one of the strings in any_terms OR\n",
    "      - all of the strings in all_terms OR\n",
    "      - the regex pattern\n",
    "    \"\"\"\n",
    "    any_terms = [t.lower() for t in (any_terms or [])]\n",
    "    all_terms = [t.lower() for t in (all_terms or [])]\n",
    "    patt = re.compile(regex, flags=re.I) if regex else None\n",
    "\n",
    "    hits = []\n",
    "    for i, t in enumerate(text_series.fillna(\"\").astype(str)):\n",
    "        tl = t.lower()\n",
    "        ok = False\n",
    "        if patt is not None and patt.search(t):\n",
    "            ok = True\n",
    "        if not ok and any_terms:\n",
    "            ok = any((k in tl) for k in any_terms)\n",
    "        if not ok and all_terms:\n",
    "            ok = all((k in tl) for k in all_terms)\n",
    "        if ok:\n",
    "            hits.append(i)\n",
    "    return hits\n",
    "\n",
    "# -------- improved local-peak finder ----------\n",
    "def local_peak(series_z, center_idx, half_window=8):\n",
    "    \"\"\"\n",
    "    Strongest |z| *within the window* around center_idx.\n",
    "    Returns (peak_idx, peak_z, dist_to_center).\n",
    "    \"\"\"\n",
    "    n = len(series_z)\n",
    "    lo, hi = max(0, center_idx - half_window), min(n, center_idx + half_window + 1)\n",
    "    window = np.abs(series_z[lo:hi])\n",
    "    if window.size == 0 or np.all(np.isnan(window)):\n",
    "        return None, np.nan, np.nan\n",
    "    rel = int(np.nanargmax(window))\n",
    "    peak_idx = lo + rel\n",
    "    peak_val = float(series_z[peak_idx])\n",
    "    return peak_idx, peak_val, int(peak_idx - center_idx)\n",
    "\n",
    "def compare_exact_then_peak(vz_hit, fz_hit, v_peak_z, f_peak_z,\n",
    "                            tie_margin=0.30, z_thr=0.80,\n",
    "                            v_peak_dist=None, f_peak_dist=None):\n",
    "    \"\"\"\n",
    "    1) EXACT: compare |vz_hit| vs |fz_hit| if either crosses z_thr (recognised at the exact chunk).\n",
    "    2) Else PEAK: compare |v_peak_z| vs |f_peak_z| if either crosses z_thr in the window.\n",
    "    3) Else: Neither.\n",
    "    Returns dict with verdicts/flags.\n",
    "    \"\"\"\n",
    "    res = {}\n",
    "    av, af = abs(vz_hit), abs(fz_hit)\n",
    "    v_exact = av >= z_thr\n",
    "    f_exact = af >= z_thr\n",
    "\n",
    "    # EXACT decision first\n",
    "    if v_exact or f_exact:\n",
    "        if (af - av) > tie_margin:\n",
    "            res[\"winner_exact\"] = \"VAD > V\"\n",
    "        elif (av - af) > tie_margin:\n",
    "            res[\"winner_exact\"] = \"V-only > VAD\"\n",
    "        else:\n",
    "            res[\"winner_exact\"] = f\"Tie (¬±{tie_margin:.2f})\"\n",
    "        res[\"decision\"] = \"EXACT\"\n",
    "        res[\"v_exact_recognised\"] = v_exact\n",
    "        res[\"f_exact_recognised\"] = f_exact\n",
    "        return res\n",
    "\n",
    "    # PEAK fallback\n",
    "    pv, pf = abs(v_peak_z), abs(f_peak_z)\n",
    "    v_peak_ok = pv >= z_thr\n",
    "    f_peak_ok = pf >= z_thr\n",
    "    if v_peak_ok or f_peak_ok:\n",
    "        if (pf - pv) > tie_margin:\n",
    "            res[\"winner_peak\"] = \"VAD > V\"\n",
    "        elif (pv - pf) > tie_margin:\n",
    "            res[\"winner_peak\"] = \"V-only > VAD\"\n",
    "        else:\n",
    "            res[\"winner_peak\"] = f\"Tie (¬±{tie_margin:.2f})\"\n",
    "        res[\"decision\"] = \"PEAK\"\n",
    "        res[\"v_peak_recognised\"] = v_peak_ok\n",
    "        res[\"f_peak_recognised\"] = f_peak_ok\n",
    "        res[\"v_peak_dist\"] = v_peak_dist\n",
    "        res[\"f_peak_dist\"] = f_peak_dist\n",
    "        return res\n",
    "\n",
    "    # Neither crossed the threshold anywhere relevant\n",
    "    res[\"decision\"] = \"NEITHER\"\n",
    "    res[\"winner_exact\"] = \"n/a\"\n",
    "    res[\"winner_peak\"] = \"n/a\"\n",
    "    res[\"v_exact_recognised\"] = False\n",
    "    res[\"f_exact_recognised\"] = False\n",
    "    res[\"v_peak_recognised\"] = False\n",
    "    res[\"f_peak_recognised\"] = False\n",
    "    res[\"v_peak_dist\"] = v_peak_dist\n",
    "    res[\"f_peak_dist\"] = f_peak_dist\n",
    "    return res\n",
    "def evaluate_turning_points_strict(book_stem,\n",
    "                                   half_window=8,\n",
    "                                   z_thr=0.80,\n",
    "                                   tie_margin=0.30):\n",
    "    \"\"\"\n",
    "    For each matched turning point:\n",
    "      - take z at the EXACT matched chunk (vz_hit, fz_hit)\n",
    "      - if neither passes z_thr, look for strongest local peak within ¬±half_window\n",
    "      - record both exact and peak metrics, with a final decision that prioritizes EXACT\n",
    "    \"\"\"\n",
    "    df = load_book_frames(book_stem)\n",
    "    vz = zscore(df[\"v_roll\"].values)\n",
    "    fz = zscore(df[\"vad_fused\"].values)\n",
    "\n",
    "    rows = []\n",
    "    for ev in TP[book_stem]:\n",
    "        any_terms = ev.get(\"any\")\n",
    "        all_terms = ev.get(\"all\")\n",
    "        regex     = ev.get(\"regex\")\n",
    "\n",
    "        hits = find_chunks_for_keywords(df[\"text\"], any_terms=any_terms, all_terms=all_terms, regex=regex)\n",
    "        hit_idx = hits[0] if hits else None\n",
    "\n",
    "        if hit_idx is None:\n",
    "            rows.append({\n",
    "                \"book\": book_stem, \"event\": ev[\"id\"], \"match_status\":\"NOT FOUND\",\n",
    "                \"match_idx\": np.nan, \"chunk_preview\":\"\", \n",
    "                \"vz_hit\": np.nan, \"fz_hit\": np.nan,\n",
    "                \"v_peak_idx\": np.nan, \"v_peak_z\": np.nan, \"v_peak_dist\": np.nan,\n",
    "                \"f_peak_idx\": np.nan, \"f_peak_z\": np.nan, \"f_peak_dist\": np.nan,\n",
    "                \"decision\":\"n/a\", \"winner_exact\":\"n/a\", \"winner_peak\":\"n/a\",\n",
    "                \"v_exact_recognised\": False, \"f_exact_recognised\": False,\n",
    "                \"v_peak_recognised\": False, \"f_peak_recognised\": False,\n",
    "                \"v_roll_hit\": np.nan, \"a_roll_hit\": np.nan, \"d_roll_hit\": np.nan, \"fused_hit\": np.nan\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        # exact z at hit\n",
    "        vz_hit = float(vz[hit_idx])\n",
    "        fz_hit = float(fz[hit_idx])\n",
    "\n",
    "        # best peaks near hit (for fallback + reporting)\n",
    "        v_pk_idx, v_pk_z, v_pk_dist = local_peak(vz, hit_idx, half_window=half_window)\n",
    "        f_pk_idx, f_pk_z, f_pk_dist = local_peak(fz, hit_idx, half_window=half_window)\n",
    "\n",
    "        dec = compare_exact_then_peak(\n",
    "            vz_hit, fz_hit, v_pk_z, f_pk_z,\n",
    "            tie_margin=tie_margin, z_thr=z_thr,\n",
    "            v_peak_dist=v_pk_dist, f_peak_dist=f_pk_dist\n",
    "        )\n",
    "\n",
    "        rows.append({\n",
    "            \"book\": book_stem,\n",
    "            \"event\": ev[\"id\"],\n",
    "            \"match_status\": \"FOUND\",\n",
    "            \"match_idx\": int(hit_idx),\n",
    "            \"chunk_preview\": preview(df.loc[hit_idx, \"text\"]),\n",
    "            # exact\n",
    "            \"vz_hit\": vz_hit, \"fz_hit\": fz_hit,\n",
    "            # peak (window)\n",
    "            \"v_peak_idx\": v_pk_idx, \"v_peak_z\": v_pk_z, \"v_peak_dist\": v_pk_dist,\n",
    "            \"f_peak_idx\": f_pk_idx, \"f_peak_z\": f_pk_z, \"f_peak_dist\": f_pk_dist,\n",
    "            # decisions\n",
    "            \"decision\": dec[\"decision\"],\n",
    "            \"winner_exact\": dec.get(\"winner_exact\",\"n/a\"),\n",
    "            \"winner_peak\": dec.get(\"winner_peak\",\"n/a\"),\n",
    "            \"v_exact_recognised\": dec.get(\"v_exact_recognised\", False),\n",
    "            \"f_exact_recognised\": dec.get(\"f_exact_recognised\", False),\n",
    "            \"v_peak_recognised\": dec.get(\"v_peak_recognised\", False),\n",
    "            \"f_peak_recognised\": dec.get(\"f_peak_recognised\", False),\n",
    "            # raw numbers at the EXACT hit (nice for reading context)\n",
    "            \"v_roll_hit\": float(df.loc[hit_idx,\"v_roll\"]),\n",
    "            \"a_roll_hit\": float(df.loc[hit_idx,\"a_roll\"]),\n",
    "            \"d_roll_hit\": float(df.loc[hit_idx,\"d_roll\"]),\n",
    "            \"fused_hit\":  float(df.loc[hit_idx,\"vad_fused\"]),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def verdict_from_z(z_v, z_fused, margin=0.30):\n",
    "    \"\"\"\n",
    "    Decide which method reacts more strongly at the event window.\n",
    "    \"\"\"\n",
    "    av, af = abs(z_v), abs(z_fused)\n",
    "    if af - av > margin:\n",
    "        return \"VAD > V\"\n",
    "    elif av - af > margin:\n",
    "        return \"V-only > VAD\"\n",
    "    else:\n",
    "        return \"Tie (¬±{:.2f})\".format(margin)\n",
    "\n",
    "def preview(text, n=220):\n",
    "    txt = \" \".join(str(text).split())\n",
    "    return (txt[:n] + \" ‚Ä¶\") if len(txt) > n else txt\n",
    "\n",
    "# ---- Turning-point catalog ---------------------------------------------------\n",
    "# You can edit/extend this dictionary freely. Each event can specify:\n",
    "#   - 'any': any of these phrases triggers a hit, OR\n",
    "#   - 'all': all of these tokens must be present (rough AND), OR\n",
    "#   - 'regex': an explicit regex (case-insensitive)\n",
    "TP = {\n",
    "    \"Frankenstein.clean\": [\n",
    "        {\"id\":\"Animation of the Creature\",\n",
    "         \"any\":[\n",
    "            \"dreary night of november\", \"dull yellow eye\", \"spark of being\"\n",
    "         ]},\n",
    "        {\"id\":\"William‚Äôs murder announced\", \"all\":[\"william\",\"murder\"]},\n",
    "        {\"id\":\"Justine‚Äôs trial / execution\", \"any\":[\"justine\",\"trial\",\"confession\",\"execut\"]},\n",
    "        {\"id\":\"Creature demands a mate\", \"any\":[\"create a female\",\"female companion\",\"mate for me\",\"female for me\"]},\n",
    "        {\"id\":\"Victor destroys the female\", \"any\":[\"tore to pieces\",\"destroyed the female\",\"the work i had begun was undone\"]},\n",
    "        {\"id\":\"Elizabeth murdered (wedding night)\", \"all\":[\"elizabeth\",\"wedding\"]},\n",
    "        {\"id\":\"Arctic pursuit & endgame\", \"any\":[\"sledge\",\"ice\",\"walton\",\"north pole\",\"arctic\"]}\n",
    "    ],\n",
    "    \"Mobi Dick.clean\": [\n",
    "        {\"id\":\"Ahab nails the doubloon / vow\",\n",
    "         \"any\":[\"spanish ounce of gold\",\"doubloon\",\"whosoever of ye raises me\",\"the quarter-deck\"]},\n",
    "        {\"id\":\"Ahab declares vengeance on Moby Dick\", \"any\":[\"it was moby dick that dismasted me\",\"i'll chase him round good hope\",\"moby dick‚Äîmoby dick\"]},\n",
    "        {\"id\":\"Typhoon / St. Elmo‚Äôs fire\", \"any\":[\"typhoon\",\"lightning\",\"candles\",\"st. elmo\"]},\n",
    "        {\"id\":\"The Symphony (Ahab & Starbuck)\", \"any\":[\"the symphony\",\"wife and child\",\"starbuck\"]},\n",
    "        {\"id\":\"The Chase‚ÄîFirst Day\", \"any\":[\"the chase‚Äîfirst day\",\"chase‚Äîfirst day\"]},\n",
    "        {\"id\":\"The Chase‚ÄîThird Day (Ahab‚Äôs death)\", \"any\":[\"the chase.‚Äîthird day\",\"third time, moby dick\",\"hemp\",\"the harpoon\"]},\n",
    "    ],\n",
    "    \"Pride and Prejudice.clean\": [\n",
    "        {\"id\":\"Meryton ball ‚Äî Darcy‚Äôs slight\", \"any\":[\"tolerable; but not handsome enough\",\"meryton\",\"assembly\"]},\n",
    "        {\"id\":\"First proposal at Hunsford\", \"any\":[\"in vain i have struggled\",\"hunsford\",\"proposal\"]},\n",
    "        {\"id\":\"Darcy‚Äôs letter & revelation\", \"all\":[\"letter\",\"wickham\"]},\n",
    "        {\"id\":\"Pemberley encounter\", \"any\":[\"pemberley\"]},\n",
    "        {\"id\":\"Lydia‚Äôs elopement\", \"all\":[\"lydia\",\"eloped\"]},\n",
    "        {\"id\":\"Bingley & Jane engaged\", \"all\":[\"bingley\",\"engaged\"]},\n",
    "        {\"id\":\"Second proposal (resolution)\", \"any\":[\"if your feelings are still what they were last april\",\n",
    "                                                   \"you are too generous to trifle with me\",\"my feelings and wishes are unchanged\"]}\n",
    "    ],\n",
    "    \"Romeo and Juliet.clean\": [\n",
    "        {\"id\":\"They meet at the Capulet feast\", \"any\":[\"holy palmers' kiss\",\"pilgrim\",\"capulet's house\"]},\n",
    "        {\"id\":\"Balcony scene\", \"any\":[\"wherefore art thou romeo\",\"balcony\"]},\n",
    "        {\"id\":\"Secret marriage (Friar‚Äôs cell)\", \"all\":[\"friar\",\"cell\",\"married\"]},\n",
    "        {\"id\":\"Mercutio slain; Tybalt slain\", \"any\":[\"a plague o' both your houses\",\"tybalt\",\"mercutio\"]},\n",
    "        {\"id\":\"Romeo banished\", \"any\":[\"banished\"]},\n",
    "        {\"id\":\"Potion plan\", \"any\":[\"vial\",\"distilling liquor\",\"slumber\"]},\n",
    "        {\"id\":\"Tomb ‚Äî deaths\", \"any\":[\"tomb\",\"thus with a kiss i die\",\"poison\",\"dagger\"]}\n",
    "    ],\n",
    "    \"The Adventures of Sherlock Holmes.clean\": [\n",
    "        # Focus on \"A Scandal in Bohemia\" (book-wide arcs still OK)\n",
    "        {\"id\":\"Masked King seeks help\", \"any\":[\"count von kramm\",\"bohemia\",\"king of bohemia\"]},\n",
    "        {\"id\":\"Godfrey Norton & sudden wedding\", \"any\":[\"godfrey norton\",\"st. monica\"]},\n",
    "        {\"id\":\"Briony Lodge stakeout\", \"any\":[\"briony lodge\",\"serpentine avenue\"]},\n",
    "        {\"id\":\"Smoke-rocket ruse / Fire!\", \"any\":[\"smoke-rocket\",\"cry of fire\",\"fire!\"]},\n",
    "        {\"id\":\"Adler‚Äôs farewell letter\", \"any\":[\"good-night, mr. sherlock holmes\",\"good night, mr. sherlock holmes\"]},\n",
    "        {\"id\":\"'The woman' outwits Holmes\", \"any\":[\"the woman\",\"i admire her intellect\",\"she has left the country\"]}\n",
    "    ],\n",
    "}\n",
    "\n",
    "BOOKS = list(TP.keys())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce284a3f-2f9d-4546-9fc7-9b07b0875dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Frankenstein.clean: exact-first eval saved ‚Üí Frankenstein.clean.turning_points_eval_exact_first.csv\n",
      "‚úî Mobi Dick.clean: exact-first eval saved ‚Üí Mobi Dick.clean.turning_points_eval_exact_first.csv\n",
      "‚úî Pride and Prejudice.clean: exact-first eval saved ‚Üí Pride and Prejudice.clean.turning_points_eval_exact_first.csv\n",
      "‚úî Romeo and Juliet.clean: exact-first eval saved ‚Üí Romeo and Juliet.clean.turning_points_eval_exact_first.csv\n",
      "‚úî The Adventures of Sherlock Holmes.clean: exact-first eval saved ‚Üí The Adventures of Sherlock Holmes.clean.turning_points_eval_exact_first.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>win</th>\n",
       "      <th>book</th>\n",
       "      <th>decision</th>\n",
       "      <th>Neither</th>\n",
       "      <th>Tie (¬±0.30)</th>\n",
       "      <th>V-only &gt; VAD</th>\n",
       "      <th>VAD &gt; V</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frankenstein.clean</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Frankenstein.clean</td>\n",
       "      <td>PEAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mobi Dick.clean</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pride and Prejudice.clean</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pride and Prejudice.clean</td>\n",
       "      <td>NEITHER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pride and Prejudice.clean</td>\n",
       "      <td>PEAK</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pride and Prejudice.clean</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Romeo and Juliet.clean</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Romeo and Juliet.clean</td>\n",
       "      <td>NEITHER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Romeo and Juliet.clean</td>\n",
       "      <td>PEAK</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The Adventures of Sherlock Holmes.clean</td>\n",
       "      <td>EXACT</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Adventures of Sherlock Holmes.clean</td>\n",
       "      <td>NEITHER</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Adventures of Sherlock Holmes.clean</td>\n",
       "      <td>PEAK</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The Adventures of Sherlock Holmes.clean</td>\n",
       "      <td>n/a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "win                                     book decision  Neither  Tie (¬±0.30)  \\\n",
       "0                         Frankenstein.clean    EXACT        0            6   \n",
       "1                         Frankenstein.clean     PEAK        0            0   \n",
       "2                            Mobi Dick.clean    EXACT        0            0   \n",
       "3                  Pride and Prejudice.clean    EXACT        0            1   \n",
       "4                  Pride and Prejudice.clean  NEITHER        1            0   \n",
       "5                  Pride and Prejudice.clean     PEAK        0            1   \n",
       "6                  Pride and Prejudice.clean      n/a        1            0   \n",
       "7                     Romeo and Juliet.clean    EXACT        0            2   \n",
       "8                     Romeo and Juliet.clean  NEITHER        1            0   \n",
       "9                     Romeo and Juliet.clean     PEAK        0            2   \n",
       "10   The Adventures of Sherlock Holmes.clean    EXACT        0            1   \n",
       "11   The Adventures of Sherlock Holmes.clean  NEITHER        1            0   \n",
       "12   The Adventures of Sherlock Holmes.clean     PEAK        0            0   \n",
       "13   The Adventures of Sherlock Holmes.clean      n/a        1            0   \n",
       "\n",
       "win  V-only > VAD  VAD > V  \n",
       "0               0        0  \n",
       "1               1        0  \n",
       "2               0        6  \n",
       "3               1        0  \n",
       "4               0        0  \n",
       "5               1        1  \n",
       "6               0        0  \n",
       "7               0        2  \n",
       "8               0        0  \n",
       "9               0        0  \n",
       "10              1        0  \n",
       "11              0        0  \n",
       "12              1        1  \n",
       "13              0        0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ Master workbook: /Users/nageshs/Desktop/college/emobook/emobook/notebooks/turning_points/turning_points_eval_exact_first.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -------- runner: write per-book CSV + master Excel ----------\n",
    "def run_tp_eval_exact_first(books=None, half_window=8, z_thr=0.80, tie_margin=0.30):\n",
    "    books = books or list(TP.keys())\n",
    "    all_out = []\n",
    "    xlsx_path = OUT_DIR / \"turning_points_eval_exact_first.xlsx\"\n",
    "    with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as xlw:\n",
    "        for b in books:\n",
    "            dfb = evaluate_turning_points_strict(b, half_window=half_window, z_thr=z_thr, tie_margin=tie_margin)\n",
    "            out_csv = OUT_DIR / f\"{b}.turning_points_eval_exact_first.csv\"\n",
    "            dfb.to_csv(out_csv, index=False)\n",
    "            dfb.to_excel(xlw, sheet_name=b[:31], index=False)\n",
    "            all_out.append(dfb)\n",
    "            print(f\"‚úî {b}: exact-first eval saved ‚Üí {out_csv.name}\")\n",
    "    # small summary\n",
    "    summary = (pd.concat(all_out, ignore_index=True)\n",
    "                 .assign(win=lambda d:\n",
    "                         np.where(d[\"decision\"].eq(\"EXACT\"), d[\"winner_exact\"],\n",
    "                         np.where(d[\"decision\"].eq(\"PEAK\"), d[\"winner_peak\"], \"Neither\")))\n",
    "                 .groupby([\"book\",\"decision\",\"win\"]).size().unstack(fill_value=0).reset_index())\n",
    "    display(summary)\n",
    "    print(f\"\\nüìÅ Master workbook: {xlsx_path}\")\n",
    "\n",
    "# ---- RUN (use your book list) ----\n",
    "run_tp_eval_exact_first(books=BOOKS, half_window=8, z_thr=0.80, tie_margin=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4bcbe3d-571a-45a0-a50c-e06af85ce951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úî Frankenstein.clean: saved Frankenstein.clean.turning_points_eval.csv (7/7 found)\n",
      "‚úî Mobi Dick.clean: saved Mobi Dick.clean.turning_points_eval.csv (6/6 found)\n",
      "‚úî Pride and Prejudice.clean: saved Pride and Prejudice.clean.turning_points_eval.csv (6/7 found)\n",
      "‚úî Romeo and Juliet.clean: saved Romeo and Juliet.clean.turning_points_eval.csv (7/7 found)\n",
      "‚úî The Adventures of Sherlock Holmes.clean: saved The Adventures of Sherlock Holmes.clean.turning_points_eval.csv (5/6 found)\n",
      "\n",
      "üìÅ Master workbook: /Users/nageshs/Desktop/college/emobook/emobook/notebooks/turning_points/turning_points_eval.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>win</th>\n",
       "      <th>book</th>\n",
       "      <th>Tie (¬±0.30)</th>\n",
       "      <th>V-only &gt; VAD</th>\n",
       "      <th>VAD &gt; V</th>\n",
       "      <th>n/a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frankenstein.clean</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mobi Dick.clean</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pride and Prejudice.clean</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romeo and Juliet.clean</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Adventures of Sherlock Holmes.clean</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "win                                     book  Tie (¬±0.30)  V-only > VAD  \\\n",
       "0                         Frankenstein.clean            4             2   \n",
       "1                            Mobi Dick.clean            0             0   \n",
       "2                  Pride and Prejudice.clean            3             2   \n",
       "3                     Romeo and Juliet.clean            4             0   \n",
       "4    The Adventures of Sherlock Holmes.clean            2             2   \n",
       "\n",
       "win  VAD > V  n/a  \n",
       "0          1    0  \n",
       "1          6    0  \n",
       "2          1    1  \n",
       "3          3    0  \n",
       "4          1    1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# ---- Run for all books & save ------------------------------------------------\n",
    "all_dfs = []\n",
    "for b in BOOKS:\n",
    "    dfb = evaluate_turning_points(b, half_window=8, margin=0.30)\n",
    "    all_dfs.append(dfb)\n",
    "    csv_path = OUT_DIR / f\"{b}.turning_points_eval.csv\"\n",
    "    dfb.to_csv(csv_path, index=False)\n",
    "    print(f\"‚úî {b}: saved {csv_path.name} ({dfb['match_status'].eq('FOUND').sum()}/{len(dfb)} found)\")\n",
    "\n",
    "# Excel with one sheet per book\n",
    "xlsx_path = OUT_DIR / \"turning_points_eval.xlsx\"\n",
    "with pd.ExcelWriter(xlsx_path, engine=\"xlsxwriter\") as xlw:\n",
    "    for dfb in all_dfs:\n",
    "        sheet = dfb['book'].iloc[0]\n",
    "        # Sheets can't be longer than 31 chars, so shorten safely\n",
    "        sheet = sheet[:31]\n",
    "        dfb.to_excel(xlw, sheet_name=sheet, index=False)\n",
    "print(f\"\\nüìÅ Master workbook: {xlsx_path}\")\n",
    "\n",
    "# Small summary table to eyeball who wins more often\n",
    "summary = (pd.concat(all_dfs, ignore_index=True)\n",
    "             .assign(win=lambda d: d['winner'].fillna(\"n/a\"))\n",
    "             .groupby(['book','win']).size().unstack(fill_value=0).reset_index())\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc0a12b-c55a-4076-8756-3841673a1be5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
