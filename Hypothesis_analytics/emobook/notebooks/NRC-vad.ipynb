{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd29ac6-ecb2-4853-a7af-5f619bdb1550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded VAD v2.1 → 44,728 unigrams, 10,073 MWEs (max len 3)\n",
      "✔ Frankenstein.clean.chunks.csv → Frankenstein.clean.scored_v21.csv | avg coverage 0.687\n",
      "✔ Mobi Dick.clean.chunks.csv → Mobi Dick.clean.scored_v21.csv | avg coverage 0.6937\n",
      "✔ Pride and Prejudice.clean.chunks.csv → Pride and Prejudice.clean.scored_v21.csv | avg coverage 0.6987\n",
      "✔ Romeo and Juliet.clean.chunks.csv → Romeo and Juliet.clean.scored_v21.csv | avg coverage 0.6788\n",
      "✔ The Adventures of Sherlock Holmes.clean.chunks.csv → The Adventures of Sherlock Holmes.clean.scored_v21.csv | avg coverage 0.6973\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book</th>\n",
       "      <th>chunks</th>\n",
       "      <th>avg_cov</th>\n",
       "      <th>mwe_hit_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Frankenstein.clean</td>\n",
       "      <td>1559</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mobi Dick.clean</td>\n",
       "      <td>4194</td>\n",
       "      <td>0.6937</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pride and Prejudice.clean</td>\n",
       "      <td>2598</td>\n",
       "      <td>0.6987</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Romeo and Juliet.clean</td>\n",
       "      <td>499</td>\n",
       "      <td>0.6788</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Adventures of Sherlock Holmes.clean</td>\n",
       "      <td>2168</td>\n",
       "      <td>0.6973</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      book  chunks  avg_cov  mwe_hit_rate\n",
       "0                       Frankenstein.clean    1559   0.6870           0.0\n",
       "1                          Mobi Dick.clean    4194   0.6937           0.0\n",
       "2                Pride and Prejudice.clean    2598   0.6987           0.0\n",
       "3                   Romeo and Juliet.clean     499   0.6788           0.0\n",
       "4  The Adventures of Sherlock Holmes.clean    2168   0.6973           0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: ../scored_v21\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd, numpy as np, unicodedata, re\n",
    "\n",
    "ROOT       = Path(\"..\")            # this notebook runs from emobook/notebooks/\n",
    "RES_DIR    = ROOT / \"resources\"\n",
    "CHUNK_DIR  = ROOT / \"chunks\"\n",
    "OUT_DIR    = ROOT / \"scored_v21\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- locate + load NRC VAD v2.1 (centered in [-1,1]) ----------\n",
    "def find_v21_path():\n",
    "    cands = [\n",
    "        RES_DIR / \"NRC-VAD-Lexicon-v2.1\" / \"NRC-VAD-Lexicon-v2.1.txt\",\n",
    "        RES_DIR / \"NRC-VAD-Lexicon-v2.1.txt\",\n",
    "    ]\n",
    "    for p in cands:\n",
    "        if p.exists():\n",
    "            return p\n",
    "    raise FileNotFoundError(\"Put NRC-VAD-Lexicon-v2.1.txt under ../resources/NRC-VAD-Lexicon-v2.1/\")\n",
    "\n",
    "def load_v21(path: Path):\n",
    "    df = pd.read_csv(path, sep=\"\\t\")\n",
    "    df[\"term\"] = df[\"term\"].astype(str).str.strip().str.lower()\n",
    "    # Build unigram and MWE dicts\n",
    "    is_mwe = df[\"term\"].str.contains(r\"\\s\")\n",
    "    uni = {t:(float(v),float(a),float(d)) for t,v,a,d in df.loc[~is_mwe,[\"term\",\"valence\",\"arousal\",\"dominance\"]].itertuples(index=False)}\n",
    "    # For MWEs, store as tuple of tokens for greedy matching\n",
    "    def tokseq(s): return tuple(re.findall(r\"[a-z]+(?:'[a-z]+)?\", s))\n",
    "    mwe_rows = df.loc[is_mwe, [\"term\",\"valence\",\"arousal\",\"dominance\"]]\n",
    "    mwe = {tokseq(t):(float(v),float(a),float(d)) for t,v,a,d in mwe_rows.itertuples(index=False)}\n",
    "    max_mwe_len = max((len(k) for k in mwe.keys()), default=1)\n",
    "    return uni, mwe, max_mwe_len\n",
    "\n",
    "UNI, MWE, MAX_MWE = load_v21(find_v21_path())\n",
    "print(f\"Loaded VAD v2.1 → {len(UNI):,} unigrams, {len(MWE):,} MWEs (max len {MAX_MWE})\")\n",
    "\n",
    "# ---------- tokenizer (simple, fast, lowercasing; keeps contractions) ----------\n",
    "TOKEN_RE = re.compile(r\"[a-z]+(?:'[a-z]+)?\", re.I)\n",
    "def tokenize(text: str):\n",
    "    t = unicodedata.normalize(\"NFC\", text)\n",
    "    return [tok.lower() for tok in TOKEN_RE.findall(t)]\n",
    "\n",
    "# ---------- negation handling (very light, optional) ----------\n",
    "NEGATORS = set(\"not no never none nobody nothing neither nor n't cannot can't don't won't isn't wasn't aren't weren't\".split())\n",
    "\n",
    "# ---------- greedy longest-match VAD scorer (prefers MWE over unigram) ----------\n",
    "def score_chunk_v21(text: str, handle_negation=True, window_after_neg=3):\n",
    "    toks = tokenize(text)\n",
    "    i, hits, n_tokens = 0, [], 0\n",
    "    flip = 0  # count down after negator\n",
    "\n",
    "    while i < len(toks):\n",
    "        tok = toks[i]\n",
    "        n_tokens += 1\n",
    "\n",
    "        # negate scope trigger\n",
    "        if handle_negation and tok in NEGATORS:\n",
    "            flip = window_after_neg\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        # try longest MWE first\n",
    "        matched = False\n",
    "        if MAX_MWE > 1:\n",
    "            L = min(MAX_MWE, len(toks)-i)\n",
    "            for n in range(L, 1, -1):\n",
    "                key = tuple(toks[i:i+n])\n",
    "                trip = MWE.get(key)\n",
    "                if trip:\n",
    "                    v,a,d = trip\n",
    "                    if flip > 0: v = -v; flip -= 1\n",
    "                    hits.append((v,a,d))\n",
    "                    i += n\n",
    "                    matched = True\n",
    "                    break\n",
    "        if matched:\n",
    "            continue\n",
    "\n",
    "        # fallback to unigram\n",
    "        trip = UNI.get(tok)\n",
    "        if trip:\n",
    "            v,a,d = trip\n",
    "            if flip > 0: v = -v; flip -= 1\n",
    "            hits.append((v,a,d))\n",
    "\n",
    "        else:\n",
    "            if flip > 0: flip -= 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if not hits:\n",
    "        return dict(v=None, a=None, d=None, n_tokens=n_tokens, n_hits=0, coverage=0.0)\n",
    "\n",
    "    arr = np.array(hits, float)\n",
    "    v_mean, a_mean, d_mean = arr.mean(axis=0).tolist()\n",
    "    return dict(\n",
    "        v=round(v_mean, 6), a=round(a_mean, 6), d=round(d_mean, 6),\n",
    "        n_tokens=n_tokens, n_hits=len(hits),\n",
    "        coverage=round(len(hits)/max(1,n_tokens), 6)\n",
    "    )\n",
    "\n",
    "# ---------- score all chunk CSVs (created earlier) ----------\n",
    "def score_all_chunks_v21():\n",
    "    rows = []\n",
    "    for csv in sorted(CHUNK_DIR.glob(\"*.chunks.csv\")):\n",
    "        df = pd.read_csv(csv)\n",
    "        out = []\n",
    "        for txt in df[\"text\"].astype(str):\n",
    "            out.append(score_chunk_v21(txt, handle_negation=True))\n",
    "        sdf = pd.DataFrame(out)\n",
    "        out_df = pd.concat([df, sdf], axis=1)\n",
    "        # convenience columns\n",
    "        out_df[\"valence_only\"] = out_df[\"v\"]               # same v dimension ([-1,1])\n",
    "        out_df[\"v01\"] = (out_df[\"v\"] + 1.0) / 2.0          # optional 0..1 view for plotting\n",
    "        out_df[\"a01\"] = (out_df[\"a\"] + 1.0) / 2.0\n",
    "        out_df[\"d01\"] = (out_df[\"d\"] + 1.0) / 2.0\n",
    "        out_df.to_csv(OUT_DIR / f\"{csv.stem.replace('.chunks','')}.scored_v21.csv\", index=False)\n",
    "        rows.append({\n",
    "            \"book\": df[\"book\"].iloc[0],\n",
    "            \"chunks\": len(df),\n",
    "            \"avg_cov\": round(out_df[\"coverage\"].mean(), 4),\n",
    "            \"mwe_hit_rate\": round(np.mean([1 if x>1 else 0 for x in [len(re.findall(r'\\\\s', t)) for t in df['text'].head(1)]]),4)  # placeholder\n",
    "        })\n",
    "        print(f\"✔ {csv.name} → {csv.stem.replace('.chunks','')}.scored_v21.csv | avg coverage {rows[-1]['avg_cov']}\")\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "summary = score_all_chunks_v21()\n",
    "display(summary)\n",
    "print(f\"Saved to: {OUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9cb7d6-c064-4e48-9f73-cfc5d3e58380",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
